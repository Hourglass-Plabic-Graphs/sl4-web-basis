{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Growth Rule Verifications\n",
    "\n",
    "In this notebook we provide Python code to verify various claims made in Section 5 of\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; [GPPSS] *Rotation-invariant web bases from hourglass plabic graphs* ([arXiv: 2306.12501](https://arxiv.org/abs/2306.12501))\n",
    "\n",
    "by Christian Gaetz, Oliver Pechenik, Stephan Pfannerer, Jessica Striker, and Joshua P. Swanson.\n",
    "\n",
    "1. Plumbings, appliances, and crystal appliances are implemented\n",
    "2. The explicit calculations in [GPPSS], Example 5.19 are checked.\n",
    "3. The 88 short rules and several of the long rules in [GPPSS], Figure 24 are verified to be good degenerations, completing the proof of Theorem 5.25.\n",
    "4. The additional good degenerations in [GPPSS], Lemma 5.22 are verified, completing its proof.\n",
    "5. Finitely many of the additional good degenerations in [GPPSS], Lemma 5.24(iv) are checked.\n",
    "6. The claim in [GPPSS], Lemma 5.26 is verified, completing its proof.\n",
    "7. The additional crystal appliance constraints for the relevant short rules in [GPPSS], Lemma 5.44 and Lemma 5.48 are verified, completing their proofs.\n",
    "8. The lex conditions in [GPPSS], Lemma 5.31 are verified, completing its proof, along with the claimed converse in Remark 5.32."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Crystals, plumbings, and appliances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes and important operations\n",
    "\n",
    "Implements:\n",
    "\n",
    "* basic operations on the crystal of words in barred and unbarred letters using the `CrystalWord` class. See [GPPSS], Section 5.3 for details.\n",
    "* `PlumbingPermutation` class, which in the notation of [GPPSS], Section 5.2 encodes a piece of a plumbing, $\\pi_s$.\n",
    "* `Plumbing` class, which is the whole plumbing $\\pi_\\bullet$.\n",
    "* `ApplianceMap` class, which is a piece of an appliance, $\\sigma_s$.\n",
    "* `Appliance` class, which is the whole appliance $\\sigma_\\bullet$.\n",
    "* `fromCrystalWord`, which constructs the crystal appliance from [GPPSS], Definition 5.16 associated to an appropriate crystal path.\n",
    "* `is_good_degeneration`, which implements [GPPSS], Theorem 5.18\n",
    "* `preserves_monotonicity`, which implements conditions in [GPPSS], Lemma 5.44 and Lemma 5.48(A),(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import zip_longest, product\n",
    "\n",
    "# global constants\n",
    "\n",
    "RANK    = 3 # the rank R, this corresponds to the number of rows-1\n",
    "LETTERS = [l for l in range(1,RANK+2)] + [-l for l in range(1,RANK+2)] # the allowed letters in the crystal words 1, 2, ..., (R+1) and -1, -2, ..., -(R+1)\n",
    "I       = [i for i in range(1,RANK+1)] # the index set for the crystals 1, 2, ..., R\n",
    "\n",
    "# crystal raising operator e(i) acting on letter l:\n",
    "def e(l, i):\n",
    "    assert i in I, f\"Index must be in the indexset I = {I}\"\n",
    "    \n",
    "    if l == i+1:\n",
    "        return i\n",
    "    \n",
    "    if l == -i:\n",
    "        return -(i+1)\n",
    "    \n",
    "    return None\n",
    "\n",
    "# crystal raising operator f(i) acting on letter l:\n",
    "def f(l, i):\n",
    "    assert i in I, f\"Index must be in the indexset I = {I}\"\n",
    "    \n",
    "    if l == i:\n",
    "        return i+1\n",
    "    \n",
    "    if l == -(i+1):\n",
    "        return -i\n",
    "    \n",
    "    return None\n",
    "\n",
    "# gives the tilde letter of l\n",
    "def tilde_letter(l):\n",
    "    return l if l>0 else RANK+2+l\n",
    "\n",
    "class CrystalWord:\n",
    "    def __init__(self, word):\n",
    "        assert all(l in LETTERS for l in word), f\"Only letters in {LETTERS} are allowed\"\n",
    "        self.word = word[:]\n",
    "        \n",
    "    def __str__(self):\n",
    "        return self.word.__str__()\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.word.__repr__()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.word)\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        return self.word[key]\n",
    "    \n",
    "    # returns the position of the left-most unmatched [ and the position of the right-most unmatched ] in the bracketing rule \n",
    "    # See [PromPerms] Section 8.3. \n",
    "    def unmatched_bracket_positions(self, i):\n",
    "        assert i in I, f\"Index must be in the indexset I = {I}\"\n",
    "        unmatched_openers = []\n",
    "        unmatched_closers = []\n",
    "        for idx, l in enumerate(self.word):\n",
    "            \n",
    "            # an opener at position idx\n",
    "            if l == i or l == -(i+1):\n",
    "                unmatched_openers.append(idx)\n",
    "                \n",
    "            # an closer at position idx\n",
    "            if l == -i or l == i+1:\n",
    "                if unmatched_openers:\n",
    "                    unmatched_openers.pop()\n",
    "                else:\n",
    "                    unmatched_closers.append(idx)\n",
    "        \n",
    "        leftmost_unmatched_opener  = None if len(unmatched_openers) == 0 else unmatched_openers[0]\n",
    "        rightmost_unmatched_closer = None if len(unmatched_closers) == 0 else unmatched_closers[-1]\n",
    "        \n",
    "        return (leftmost_unmatched_opener, rightmost_unmatched_closer)\n",
    "        \n",
    "    # applies the crystal raising operator e(i) to the word and returns the new word and if return_position=True  the position where raising operator was acting\n",
    "    def e(self, i, return_position = False):\n",
    "        assert i in I, f\"Index must be in the indexset I = {I}\"\n",
    "        _, idx = self.unmatched_bracket_positions(i)\n",
    "        if idx is not None:\n",
    "            new_word = self.word.copy()\n",
    "            new_word[idx] = e(new_word[idx], i)\n",
    "            if return_position:\n",
    "                return CrystalWord(new_word), idx\n",
    "            else:\n",
    "                return CrystalWord(new_word)\n",
    "        \n",
    "        if return_position:\n",
    "            return None, None\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    # applies the crystal lowering operator f(i) to the word and returns the new word and if return_position=True the position where lowering operator was acting\n",
    "    def f(self, i, return_position = False):\n",
    "        assert i in I, f\"Index must be in the indexset I = {I}\"\n",
    "        idx, _ = self.unmatched_bracket_positions(i)\n",
    "        if idx is not None:\n",
    "            new_word = self.word.copy()\n",
    "            new_word[idx] = f(new_word[idx], i)\n",
    "            if return_position:\n",
    "                return CrystalWord(new_word), idx\n",
    "            else:\n",
    "                return CrystalWord(new_word)\n",
    "        \n",
    "        if return_position:\n",
    "            return None, None\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def es(self, e_path, return_positions = False):\n",
    "        current_word = self\n",
    "        positions = []\n",
    "        for i in e_path:\n",
    "            current_word, idx = current_word.e(i, return_position = True)\n",
    "            if current_word is None:\n",
    "                break\n",
    "            positions.append(idx)\n",
    "        if return_positions:\n",
    "            return current_word, zip(positions, e_path)\n",
    "        else:\n",
    "            return current_word\n",
    "        \n",
    "    def fs(self, f_path, return_positions = False):\n",
    "        current_word = self\n",
    "        positions = []\n",
    "        for i in f_path:\n",
    "            current_word, idx = current_word.f(i, return_position = True)\n",
    "            if current_word is None:\n",
    "                break\n",
    "            positions.append(idx)\n",
    "        if return_positions:\n",
    "            return current_word, zip(positions, f_path)\n",
    "        else:\n",
    "            return current_word\n",
    "    \n",
    "    # returns true if the word is a highest weight word, else false\n",
    "    def is_heighest_weight(self):\n",
    "        return all(self.e(i) is None for i in I)\n",
    "        \n",
    "    # returns true if the word is a lowest weight word, else false\n",
    "    def is_lowest_weight(self):\n",
    "        return all(self.f(i) is None for i in I)\n",
    "    \n",
    "    # cut away the first letter and apply raising operator to get to hwe\n",
    "    def cut_left(self, return_positions = False):\n",
    "        assert self.is_heighest_weight(), \"word must be a highest weight element\"\n",
    "        new_word = CrystalWord(self.word[1:])\n",
    "        e_path = next(new_word.all_paths_to_top())\n",
    "        return new_word.es(e_path, return_positions)\n",
    "        \n",
    "    # cut away the last letter and apply lowering operators to get to hwe\n",
    "    def cut_right(self, return_positions = False):\n",
    "        assert self.is_lowest_weight(), \"word must be a lowest weight element\"\n",
    "        new_word = CrystalWord(self.word[:-1])\n",
    "        f_path = next(new_word.all_paths_to_bottom())\n",
    "        return new_word.fs(f_path, return_positions)\n",
    "    \n",
    "    # returns all paths to the heighest weight element in lexicographic order\n",
    "    def all_paths_to_top(self):\n",
    "        if(self.is_heighest_weight()):\n",
    "            yield []\n",
    "        else:\n",
    "            for i in I:\n",
    "                new_word = self.e(i)\n",
    "                if new_word is not None:\n",
    "                    for p in new_word.all_paths_to_top():\n",
    "                        yield [i]+p\n",
    "    \n",
    "    # returns all paths to the lowest weight element in lexicographic order\n",
    "    def all_paths_to_bottom(self):\n",
    "        if(self.is_lowest_weight()):\n",
    "            yield []\n",
    "        else:\n",
    "            for i in I:\n",
    "                new_word = self.f(i)\n",
    "                if new_word is not None:\n",
    "                    for p in new_word.all_paths_to_bottom():\n",
    "                        yield [i]+p\n",
    "                        \n",
    "    def tilde(self):\n",
    "        return tuple(tilde_letter(l) for l in self)\n",
    "\n",
    "    def is_tilde_lex_smaller(self, other):\n",
    "        other = CrystalWord(other[:])\n",
    "        return self.tilde() < other.tilde()\n",
    "    \n",
    "# A plumbing permutation of type (m,n) is a Permutation of {(\"a\",0), (\"a\",1), ..., (\"a\", m-1), (\"b\",0), (\"b\",1), ..., (\"b\", n-1)} and is represented as two lists\n",
    "# of lengths m and n respectively. The first list contains the images (\"a\",0), (\"a\",1), ..., (\"a\", m-1) and the second list the images of (\"b\",0), ..., (\"b\", n-1)\n",
    "\n",
    "class PlumbingPermutation():\n",
    "    def __init__(self, permutation):\n",
    "        self.type = len(permutation[0]), len(permutation[1])\n",
    "        self.a, self.b = permutation[0], permutation[1]\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return [self.a, self.b].__repr__()\n",
    "    \n",
    "    def __call__(self, e):\n",
    "        s, idx = e\n",
    "        if s == \"a\":\n",
    "            return self.a[idx]\n",
    "        else:\n",
    "            return self.b[idx]\n",
    "    def __eq__(self, other):\n",
    "        return self.a == other.a and self.b == other.b\n",
    "    \n",
    "    # Defines horizontal gluing of Plumbing permutations\n",
    "    def __add__(self, other):\n",
    "        def offset(e, da, db):\n",
    "            s, idx = e\n",
    "            if s == \"a\":\n",
    "                return (\"a\", idx+da)\n",
    "            else:\n",
    "                return (\"b\", idx+db)\n",
    "            \n",
    "        a_offset, b_offset = self.type\n",
    "        a = self.a + [offset(e, a_offset, b_offset) for e in other.a]\n",
    "        b = self.b + [offset(e, a_offset, b_offset) for e in other.b]\n",
    "        \n",
    "        return PlumbingPermutation([a,b])\n",
    "    \n",
    "    # Defines the composition of two plumbings self*other\n",
    "    def __mul__(self, other):\n",
    "        def swap_ab(e):\n",
    "            s, idx = e\n",
    "            if s == \"a\":\n",
    "                return (\"b\", idx)\n",
    "            else:\n",
    "                return (\"a\", idx)\n",
    "        \n",
    "        # returning NotImplemented is important so that __rmul__ is triggered in the case (int)*(PlumbingPermutation)\n",
    "        if not isinstance(other, PlumbingPermutation):\n",
    "            return NotImplemented\n",
    "        assert other.type[1] == self.type[0], f\"Cannot compose PlumbingPermutations of types {self.type} and {other.type}\"\n",
    "        a = [None for _ in other.a]\n",
    "        b = [None for _ in self.b]\n",
    "        for idx in range(len(a)):\n",
    "            e = ('a', idx)\n",
    "            while True:\n",
    "                e = other(e)\n",
    "                if e[0] == \"a\":\n",
    "                    break\n",
    "                e = swap_ab(e)\n",
    "                e = self(e)\n",
    "                if e[0] == \"b\":\n",
    "                    break\n",
    "                e = swap_ab(e)\n",
    "            a[idx] = e\n",
    "            \n",
    "        for idx in range(len(b)):\n",
    "            e = ('b', idx)\n",
    "            while True:\n",
    "                e = self(e)\n",
    "                if e[0] == \"b\":\n",
    "                    break\n",
    "                e = swap_ab(e)\n",
    "                e = other(e)\n",
    "                if e[0] == \"a\":\n",
    "                    break\n",
    "                e = swap_ab(e)\n",
    "            b[idx] = e\n",
    "            \n",
    "        return PlumbingPermutation([a,b])\n",
    "    \n",
    "    def __rmul__(self, other):\n",
    "        assert isinstance(other, int), \"Cannot multiply those types\"\n",
    "        return sum((self for _ in range(other-1)), self)\n",
    "        \n",
    "\n",
    "class Plumbing():\n",
    "    def __init__(self, permutations):\n",
    "        assert len(permutations) == RANK, f\"A plumbing consists of {RANK} permutations\"\n",
    "        self.permutations = permutations\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.permutations.__repr__()\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return all([p==s for p,s in zip(self, other)])\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        return self.permutations[key]\n",
    "    \n",
    "    def __call__(self, s):\n",
    "        return self[s-1]\n",
    "    \n",
    "    def __mul__(self, other):\n",
    "        if not isinstance(other, Plumbing):\n",
    "            return NotImplemented\n",
    "        return Plumbing([p*s for p,s in zip(self, other)])\n",
    "    \n",
    "    def __rmul__(self, other):\n",
    "        return Plumbing([p*other for p in self])\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        return Plumbing([p+s for p,s in zip(self, other)])\n",
    "    \n",
    "    def __rmul__(self, other):\n",
    "        return Plumbing([other*p for p in self])\n",
    "\n",
    "# An appliance map is a function from {('b', 0), ('b', 1), ..., ('b', l)} to {('a', 0), ('a', 1), ..., ('a', k), ('b', 0), ('b', 1), ..., ('b', l), ('c', 0), ('c', 1), ..., ('c', m)}\n",
    "# given as a list containing the images of ('b', 0), ('b', 1), ..., ('b', l)\n",
    "\n",
    "class ApplianceMap():\n",
    "    def __init__(self, function):\n",
    "        self.map = function\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.map.__repr__()\n",
    "        \n",
    "    def __call__(self, e):\n",
    "        s, idx = e\n",
    "        return self.map[idx]\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return self.map == other.map\n",
    "    \n",
    "    # multiplication of self*other where other is a plumbing permutation\n",
    "    def __mul__(self, other):\n",
    "        assert other.type[1] == len(self.map), f\"Cannot act with PlumbingPermutations of type {other.type} on ApplianceMap of length {len(self.map)}\"\n",
    "        new_map = [None for _ in other.a]\n",
    "        for idx in range(len(new_map)):\n",
    "            e = ('a', idx)\n",
    "            while True:\n",
    "                e = other(e)\n",
    "                if e[0] == \"a\": # plumbing maps element of A to A.\n",
    "                    e = ('b', e[1]) # in the appliance set is called B.\n",
    "                    break\n",
    "                e = self(e)\n",
    "                if e[0] != \"b\": #if appliance maps to A or C\n",
    "                    break\n",
    "            new_map[idx] = e\n",
    "            \n",
    "        return ApplianceMap(new_map)\n",
    "    \n",
    "class Appliance():\n",
    "    def __init__(self, appliance_maps):\n",
    "        self.maps = appliance_maps\n",
    "        \n",
    "    # creates the crystal appliance as in Definition 5.9\n",
    "    # word is a Crystal word\n",
    "    # e_path is a squence of raising operators that bring word to the highest weight element\n",
    "    # f_path is a squence of lowering operators that bring word to the lowest weight element\n",
    "    # if transposed is set to true (the default here), the transposed Appliance is returned.\n",
    "    @classmethod\n",
    "    def fromCrystalWord(cls, word, e_path, f_path, transposed = True):\n",
    "        hwe, e_positions = word.es(e_path, return_positions = True)\n",
    "        lwe, f_positions = word.fs(f_path, return_positions = True)\n",
    "        assert hwe.is_heighest_weight(), \"given e-path doesn't go to highest weight element\"\n",
    "        assert lwe.is_lowest_weight(), \"given f-path doesn't go to lowers weight element\"\n",
    "        \n",
    "        appliance_maps = [[None for _ in range(len(word))] for _ in I]\n",
    "        \n",
    "        # upper part (B -> A), phase I:\n",
    "        for k, pi in enumerate(e_positions):\n",
    "            p,i = pi\n",
    "            appliance_maps[i-1][p] = ('a', k)\n",
    "            \n",
    "        # lower part (B -> C), phase III:\n",
    "        for k, pi in enumerate(f_positions):\n",
    "            p,i = pi\n",
    "            appliance_maps[i-1][p] = ('c', len(f_path)-k-1)\n",
    "        \n",
    "        # middle part (B -> B) upper half, phase II:\n",
    "        cut = hwe\n",
    "        for k in range(len(hwe)):\n",
    "            cut, pos = cut.cut_left(return_positions=True)\n",
    "            for p, i in pos: # p is the position in the word, i is the index of the raising operator\n",
    "                appliance_maps[i-1][p+k+1] = ('b', k)\n",
    "                \n",
    "        # middle part (B -> B) lower half, phase IV:\n",
    "        cut = lwe\n",
    "        for k in range(len(hwe),0,-1):\n",
    "            cut, pos = cut.cut_right(return_positions=True)\n",
    "            for p, i in pos: # p is the position in the word, i is the index of the raising operator\n",
    "                appliance_maps[i-1][p] = ('b', k-1)        \n",
    "        if transposed:\n",
    "            return Appliance([ApplianceMap(m) for m in appliance_maps[::-1]])\n",
    "        else:\n",
    "            return Appliance([ApplianceMap(m) for m in appliance_maps])\n",
    "    \n",
    "    @classmethod\n",
    "    def crystal_appliances(cls, v, transposed = True):\n",
    "        v = CrystalWord(v)\n",
    "        for up,down in product(v.all_paths_to_top(), v.all_paths_to_bottom()):\n",
    "            yield cls.fromCrystalWord(v, up, down, transposed=transposed)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.maps.__repr__()\n",
    "        \n",
    "    def __eq__(self, other):\n",
    "        return all(f==g for f,g in zip(self, other))\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        return self.maps[key]\n",
    "    \n",
    "    def __call__(self, s):\n",
    "        return self[s-1]\n",
    "    \n",
    "    def __mul__(self, other):\n",
    "        return Appliance([g*p for g,p in zip(self, other)])\n",
    "\n",
    "def is_good_degeneration(v, w, plumbing):\n",
    "    v = CrystalWord(v)\n",
    "    w = CrystalWord(w)\n",
    "    if any(p!=q for p,q in zip_longest(v.all_paths_to_top(), w.all_paths_to_top())) or any(p!=q for p,q in zip_longest(v.all_paths_to_bottom(), w.all_paths_to_bottom())):\n",
    "        print(\"Paths not pairwise equal\")\n",
    "        return False\n",
    "    \n",
    "    return all(Appliance.fromCrystalWord(v, up, down) == Appliance.fromCrystalWord(w, up, down)*plumbing for up, down in product(v.all_paths_to_top(), v.all_paths_to_bottom()))\n",
    "\n",
    "def is_crossing(ac, bd):\n",
    "    '''Determines if pairs {a,c} and {b,d} from a totally ordered alphabet form a crossing.\n",
    "       Throws an error if a,b,c,d are not all distinct.'''\n",
    "    if min(ac) > min(bd):\n",
    "        ac,bd = bd,ac\n",
    "    a,c = ac\n",
    "    b,d = bd\n",
    "    assert len({a,b,c,d})==4, \"Input not all distinct, crossing undefined\"\n",
    "    if a > c:\n",
    "        a,c = c,a\n",
    "    if b > d:\n",
    "        b,d = d,b\n",
    "    return a<b<c<d\n",
    "\n",
    "def is_intersecting(ax,by):\n",
    "    '''Determines if pairs (a,x) and (b,y) from a totally ordered alphabet form an intersection.\n",
    "       Throws an error if a,b not distinct.'''\n",
    "    a,x=ax\n",
    "    b,y=by\n",
    "    assert a!=b, \"Intersection undefined, a=b\"\n",
    "    if x==b or y==a or x==y:\n",
    "        return True\n",
    "    return is_crossing(ax,by)\n",
    "\n",
    "def preserves_monotonicity(v, condition_type):\n",
    "    '''Assumes the X is at the first two indexes, which are either both positive or the first\n",
    "       is negative and the second is positive, with witnesses on the right. condition_type is either\n",
    "       'A' in the first case or 'B' in the second case.'''\n",
    "    v = CrystalWord(v)\n",
    "    a = ('b',0)\n",
    "    b = ('b',1)\n",
    "\n",
    "    for up, down in product(v.all_paths_to_top(), v.all_paths_to_bottom()):\n",
    "        rho = Appliance.fromCrystalWord(v, up, down, transposed=False)\n",
    "\n",
    "        # Check trip2, trip2 conditions\n",
    "        if rho(2)(a) == b:\n",
    "            return False\n",
    "        if is_crossing( (a, rho(2)(a)), (b, rho(2)(b)) ):\n",
    "            return False\n",
    "        \n",
    "        # Check trip1, trip2 conditions\n",
    "        if condition_type=='A':\n",
    "            if (is_intersecting( (b, rho(1)(b)), (a, rho(2)(a)) ) or\n",
    "                is_intersecting( (a, rho(3)(a)), (b, rho(2)(b)) ) or\n",
    "                is_intersecting( (b, rho(3)(b)), (a, rho(2)(a)) ) or\n",
    "                is_intersecting( (a, rho(1)(a)), (b, rho(2)(b)) )):\n",
    "                return False\n",
    "        \n",
    "        if condition_type=='B':\n",
    "            if (is_intersecting( (b, rho(1)(b)), (a, rho(2)(a)) ) or\n",
    "                is_intersecting( (a, rho(3)(a)), (b, rho(2)(b)) ) or\n",
    "                is_intersecting( (b, rho(3)(b)), (a, rho(2)(a)) )):\n",
    "                return False\n",
    "            \n",
    "            c = rho(3)(b)\n",
    "            if c <= b or b[0] != c[0]:\n",
    "                return False\n",
    "\n",
    "            for i in range(b[1],c[1]+1):\n",
    "                t=(b[0],i)\n",
    "                if is_intersecting( (a, rho(1)(a)), (t, rho(2)(t)) ):\n",
    "                    return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Building blocks for plumbings\n",
    "bar     = Plumbing([PlumbingPermutation([[('b',0)],[('a',0)]]) for _ in I])\n",
    "\n",
    "cup     = Plumbing([PlumbingPermutation([[('a',1), ('a',0)],[]]) for _ in I])\n",
    "\n",
    "X_pp_pp = Plumbing([PlumbingPermutation([[('a',1), ('b',0)], [('b',1), ('a',0)]]),\n",
    "                    PlumbingPermutation([[('b',1), ('b',0)], [('a',1), ('a',0)]]),\n",
    "                    PlumbingPermutation([[('b',1), ('a',0)], [('a',1), ('b',0)]])])\n",
    "\n",
    "X_mm_mm = Plumbing([PlumbingPermutation([[('b',1), ('a',0)], [('a',1), ('b',0)]]),\n",
    "                    PlumbingPermutation([[('b',1), ('b',0)], [('a',1), ('a',0)]]),\n",
    "                    PlumbingPermutation([[('a',1), ('b',0)], [('b',1), ('a',0)]])])\n",
    "\n",
    "X_pp_mm = Plumbing([PlumbingPermutation([[('a',1), ('b',1)], [('a',0), ('b',0)]]),\n",
    "                    PlumbingPermutation([[('b',1), ('b',0)], [('a',1), ('a',0)]]),\n",
    "                    PlumbingPermutation([[('b',0), ('a',0)], [('b',1), ('a',1)]])])\n",
    "\n",
    "X_mm_pp = Plumbing([PlumbingPermutation([[('b',0), ('a',0)], [('b',1), ('a',1)]]),\n",
    "                    PlumbingPermutation([[('b',1), ('b',0)], [('a',1), ('a',0)]]),\n",
    "                    PlumbingPermutation([[('a',1), ('b',1)], [('a',0), ('b',0)]])])\n",
    "\n",
    "\n",
    "X_pm_mp = Plumbing([PlumbingPermutation([[('b',1), ('b',0)], [('a',0), ('a',1)]]),\n",
    "                    PlumbingPermutation([[('b',1), ('b',0)], [('a',1), ('a',0)]]),\n",
    "                    PlumbingPermutation([[('b',0), ('b',1)], [('a',1), ('a',0)]])])\n",
    "\n",
    "X_mp_pm = Plumbing([PlumbingPermutation([[('b',0), ('b',1)], [('a',1), ('a',0)]]),\n",
    "                    PlumbingPermutation([[('b',1), ('b',0)], [('a',1), ('a',0)]]),\n",
    "                    PlumbingPermutation([[('b',1), ('b',0)], [('a',0), ('a',1)]])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: check [GPPSS], Figure 29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create plumbings and appliances\n",
    "pi         = PlumbingPermutation([[('b',2), ('b',0)], [('a',1),('a',0),('b',1)]])\n",
    "sigma      = PlumbingPermutation([[('a',3), ('b',0), ('a',1), ('a',0)], [('b',1), ('a',2)]])\n",
    "pi_sigma   = PlumbingPermutation([[('a',3), ('b',2), ('a',1), ('a',0)], [('a',2), ('b',0), ('b',1)]])\n",
    "g          = ApplianceMap([('a',0), ('b',2), ('c',1)])\n",
    "g_pi_sigma = ApplianceMap([('b',3), ('c',1), ('b',1), ('b',0)])\n",
    "\n",
    "# Check compositions are as claimed\n",
    "pi_sigma == pi*sigma and g_pi_sigma == g*(pi*sigma) == (g*pi)*sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Check {GPPSS], Example 5.19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v = [-3, 2, 4]\n",
      "\n",
      "Phase I. Raising path: \\vec{e} = [1, 3, 3, 2]\n",
      "  Highest weight: [-4, 1, 2]\n",
      "  Applied: e_1 at 2, then e_3 at 3, then e_3 at 1, then e_2 at 3\n",
      "\n",
      "Phase II. Upper triangle\n",
      "  Highest weight: [1, 2]\n",
      "  Applied: \n",
      "  Highest weight: [1]\n",
      "  Applied: e_1 at 1\n",
      "  Highest weight: []\n",
      "  Applied: \n",
      "\n",
      "Phase III. Lowering path: \\vec{f} = [2, 2, 1]\n",
      "  Lowest weight: [-1, 3, 4]\n",
      "  Applied: f_2 at 1, then f_2 at 2, then f_1 at 1\n",
      "\n",
      "Phase IV. Lower triangle\n",
      "  Highest weight: [-1, 4]\n",
      "  Applied: f_3 at 2\n",
      "  Highest weight: [-1]\n",
      "  Applied: \n",
      "  Highest weight: []\n",
      "  Applied: \n",
      "\n",
      "Crystal appliance of [-3, 2, 4] with [1, 3, 3, 2], [2, 2, 1]:\n",
      "  \\rho_1^\\top = [('a', 2), ('b', 2), ('a', 1)]\n",
      "  \\rho_2^\\top = [('c', 2), ('c', 1), ('a', 3)]\n",
      "  \\rho_3^\\top = [('c', 0), ('a', 0), ('b', 1)]\n",
      "  Note: for Example 5.19, use ('a',0)=1, ('a',1)=2, ('a',2)=3, ('a',3)=4, ('b',0)=5, ('b',1)=6, ('b',2)=7, ('c',0)=8, ('c',1)=9, ('c',2)=10\n",
      "\n",
      "Is (\\rho_\\bullet^\\top for [-3, 2, 4]) = (\\rho_\\bullet^\\top for [-3, -1, -3]) . \\pi? True\n"
     ]
    }
   ],
   "source": [
    "v  = CrystalWord([-3,2,4])\n",
    "vp = CrystalWord([-3,-1,-3])\n",
    "\n",
    "def show_apps(apps,ef='e'):\n",
    "    print(\"  Applied:\", \", then \".join([f\"{ef}_{s} at {p+1}\" for p,s in apps]))\n",
    "\n",
    "\n",
    "print(\"v =\", v)\n",
    "print()\n",
    "\n",
    "es = next(v.all_paths_to_top())\n",
    "assert es == next(vp.all_paths_to_top())\n",
    "\n",
    "print(\"Phase I. Raising path: \\\\vec{e} =\", es)\n",
    "\n",
    "vhw,apps = v.es(es, return_positions=True)\n",
    "print(\"  Highest weight:\", vhw)\n",
    "show_apps(apps)\n",
    "print()\n",
    "\n",
    "print(\"Phase II. Upper triangle\")\n",
    "while len(vhw)>0:\n",
    "    vhw,apps = vhw.cut_left(return_positions=True)\n",
    "    print(\"  Highest weight:\", vhw)\n",
    "    show_apps(apps)\n",
    "\n",
    "fs = next(v.all_paths_to_bottom())\n",
    "assert fs == next(vp.all_paths_to_bottom())\n",
    "print()\n",
    "\n",
    "print(\"Phase III. Lowering path: \\\\vec{f} =\", fs)\n",
    "\n",
    "vlw,apps = v.fs(fs, return_positions=True)\n",
    "print(\"  Lowest weight:\", vlw)\n",
    "show_apps(apps,'f')\n",
    "print()\n",
    "\n",
    "print(\"Phase IV. Lower triangle\")\n",
    "while len(vlw)>0:\n",
    "    vlw,apps = vlw.cut_right(return_positions=True)\n",
    "    print(\"  Highest weight:\", vlw)\n",
    "    show_apps(apps,'f')\n",
    "print()\n",
    "\n",
    "va = Appliance.fromCrystalWord(v, es, fs) # Note: appliances are by default constructed transposed\n",
    "print(f\"Crystal appliance of {v} with {es}, {fs}:\")\n",
    "print(\"  \\\\rho_1^\\\\top =\",va(1))\n",
    "print(\"  \\\\rho_2^\\\\top =\",va(2))\n",
    "print(\"  \\\\rho_3^\\\\top =\",va(3))\n",
    "print(\"  Note: for Example 5.19, use ('a',0)=1, ('a',1)=2, ('a',2)=3, ('a',3)=4, ('b',0)=5, ('b',1)=6, ('b',2)=7, ('c',0)=8, ('c',1)=9, ('c',2)=10\")\n",
    "print()\n",
    "\n",
    "vpa = Appliance.fromCrystalWord(vp, es, fs)\n",
    "pi = bar+X_pp_mm\n",
    "print(f\"Is (\\\\rho_\\\\bullet^\\\\top for {v}) = (\\\\rho_\\\\bullet^\\\\top for {vp}) . \\\\pi?\", va == vpa*pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Verify short and long rules in Figure 24 are good degenerations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Non example\n",
    "is_good_degeneration([-4,2],[2,-4], X_mp_pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example\n",
    "is_good_degeneration([-4,2,4],[2,-4,4], X_mp_pm+bar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the 88 short rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "growth_rules = [\n",
    "    ([1,-1],[],cup,None),\n",
    "    ([-4,4],[],cup,None),\n",
    "    \n",
    "    ([1,-2],[-2,1],X_pm_mp,'A'),\n",
    "    ([2,-1],[-1,2],X_pm_mp,'A'),\n",
    "    ([-3,4],[4,-3],X_mp_pm,None),\n",
    "    ([-4,3],[3,-4],X_mp_pm,None),\n",
    "    \n",
    "    ([2,-2],[-1,1],X_pm_mp,'A'),\n",
    "    ([-3,3],[4,-4],X_mp_pm,None),\n",
    "    \n",
    "    ([1,-3,-1],[-3,1,-1],X_pm_mp+bar,'A'),#\n",
    "    ([1,-3,2],[-3,1,2],X_pm_mp+bar,'A'),\n",
    "    ([1,3,-1],[1,-1,3],bar+X_pm_mp,None),#\n",
    "    ([-2,3,-1],[-2,-1,3],bar+X_pm_mp,None),\n",
    "    ([-4,-2,4],[-4,4,-2],bar+X_mp_pm,None),#\n",
    "    ([3,-2,4],[3,4,-2],bar+X_mp_pm,None),\n",
    "    ([-4,2,4],[2,-4,4],X_mp_pm+bar,None),#\n",
    "    ([-4,2,-3],[2,-4,-3],X_mp_pm+bar,None),\n",
    "    \n",
    "    ([1,2,-1],[2,1,-1],X_pp_pp+bar,'B'),#\n",
    "    ([1,2,2],[2,1,2],X_pp_pp+bar,'B'),\n",
    "    ([1,-2,-1],[1,-1,-2],bar+X_mm_mm,None),#\n",
    "    ([-2,-2,-1],[-2,-1,-2],bar+X_mm_mm,None),\n",
    "    ([-4,3,4],[-4,4,3],bar+X_pp_pp,None),#\n",
    "    ([3,3,4],[3,4,3],bar+X_pp_pp,None),\n",
    "    ([-4,-3,4],[-3,-4,4],X_mm_mm+bar,None),#\n",
    "    ([-4,-3,-3],[-3,-4,-3],X_mm_mm+bar,None),\n",
    "    \n",
    "    ([1,3,-1],[3,1,-1],X_pp_pp+bar,'B'),#\n",
    "    ([1,3,2],[3,1,2],X_pp_pp+bar,'B'),\n",
    "    ([1,3,3],[3,1,3],X_pp_pp+bar,'B'),\n",
    "    ([1,-3,-1],[1,-1,-3],bar+X_mm_mm,None),#\n",
    "    ([-2,-3,-1],[-2,-1,-3],bar+X_mm_mm,None),\n",
    "    ([-3,-3,-1],[-3,-1,-3],bar+X_mm_mm,None),\n",
    "    ([-4,2,4],[-4,4,2],bar+X_pp_pp,None),#\n",
    "    ([3,2,4],[3,4,2],bar+X_pp_pp,None),\n",
    "    ([2,2,4],[2,4,2],bar+X_pp_pp,None),\n",
    "    ([-4,-2,4],[-2,-4,4],X_mm_mm+bar,None),#\n",
    "    ([-4,-2,-3],[-2,-4,-3],X_mm_mm+bar,None),\n",
    "    ([-4,-2,-2],[-2,-4,-2],X_mm_mm+bar,None),\n",
    "    \n",
    "    ([1,4,-1],[4,1,-1],X_pp_pp+bar,'B'),#\n",
    "    ([1,4,2],[4,1,2],X_pp_pp+bar,'B'),\n",
    "    ([1,4,3],[4,1,3],X_pp_pp+bar,'B'),\n",
    "    ([1,4,4],[4,1,4],X_pp_pp+bar,'B'),\n",
    "    ([1,-4,-1],[1,-1,-4],bar+X_mm_mm,None),#\n",
    "    ([-2,-4,-1],[-2,-1,-4],bar+X_mm_mm,None),\n",
    "    ([-3,-4,-1],[-3,-1,-4],bar+X_mm_mm,None),\n",
    "    ([-4,-4,-1],[-4,-1,-4],bar+X_mm_mm,None),\n",
    "    ([-4,1,4],[-4,4,1],bar+X_pp_pp,None),#\n",
    "    ([3,1,4],[3,4,1],bar+X_pp_pp,None),\n",
    "    ([2,1,4],[2,4,1],bar+X_pp_pp,None),\n",
    "    ([1,1,4],[1,4,1],bar+X_pp_pp,None),\n",
    "    ([-4,-1,4],[-1,-4,4],X_mm_mm+bar,None),#\n",
    "    ([-4,-1,-3],[-1,-4,-3],X_mm_mm+bar,None),\n",
    "    ([-4,-1,-2],[-1,-4,-2],X_mm_mm+bar,None),\n",
    "    ([-4,-1,-1],[-1,-4,-1],X_mm_mm+bar,None),\n",
    "    \n",
    "    ([1,2,-3],[-3,-4,-3],X_pp_mm+bar,None),#\n",
    "    ([1,2,4],[-3,-4,4],X_pp_mm+bar,None),\n",
    "    ([3,-2,-1],[3,4,3],bar+X_mm_pp,None),#\n",
    "    ([-4,-2,-1],[-4,4,3],bar+X_mm_pp,None),\n",
    "    ([-2,3,4],[-2,-1,-2],bar+X_pp_mm,None),#\n",
    "    ([1,3,4],[1,-1,-2],bar+X_pp_mm,None),\n",
    "    ([-4,-3,2],[2,1,2],X_mm_pp+bar,'B'),#\n",
    "    ([-4,-3,-1],[2,1,-1],X_mm_pp+bar,'B'),\n",
    "    \n",
    "    ([1,3,-2],[-2,-4,-2],X_pp_mm+bar,None),#\n",
    "    ([1,3,-3],[-2,-4,-3],X_pp_mm+bar,None),\n",
    "    ([1,3,4],[-2,-4,4],X_pp_mm+bar,None),\n",
    "    ([2,-3,-1],[2,4,2],bar+X_mm_pp,None),#\n",
    "    ([3,-3,-1],[3,4,2],bar+X_mm_pp,None),\n",
    "    ([-4,-3,-1],[-4,4,2],bar+X_mm_pp,None),\n",
    "    ([-3,2,4],[-3,-1,-3],bar+X_pp_mm,None),#\n",
    "    ([-2,2,4],[-2,-1,-3],bar+X_pp_mm,None),\n",
    "    ([1,2,4],[1,-1,-3],bar+X_pp_mm,None),\n",
    "    ([-4,-2,3],[3,1,3],X_mm_pp+bar,'B'),#\n",
    "    ([-4,-2,2],[3,1,2],X_mm_pp+bar,'B'),\n",
    "    ([-4,-2,-1],[3,1,-1],X_mm_pp+bar,'B'),\n",
    "    \n",
    "    ([2,3,-1],[-1,-4,-1],X_pp_mm+bar,None),#\n",
    "    ([2,3,-2],[-1,-4,-2],X_pp_mm+bar,None),\n",
    "    ([2,3,-3],[-1,-4,-3],X_pp_mm+bar,None),\n",
    "    ([2,3,4],[-1,-4,4],X_pp_mm+bar,None),\n",
    "    ([1,-3,-2],[1,4,1],bar+X_mm_pp,None),#\n",
    "    ([2,-3,-2],[2,4,1],bar+X_mm_pp,None),\n",
    "    ([3,-3,-2],[3,4,1],bar+X_mm_pp,None),\n",
    "    ([-4,-3,-2],[-4,4,1],bar+X_mm_pp,None),\n",
    "    ([-4,2,3],[-4,-1,-4],bar+X_pp_mm,None),#\n",
    "    ([-3,2,3],[-3,-1,-4],bar+X_pp_mm,None),\n",
    "    ([-2,2,3],[-2,-1,-4],bar+X_pp_mm,None),\n",
    "    ([1,2,3],[1,-1,-4],bar+X_pp_mm,None),\n",
    "    ([-3,-2,4],[4,1,4],X_mm_pp+bar,'B'),#\n",
    "    ([-3,-2,3],[4,1,3],X_mm_pp+bar,'B'),\n",
    "    ([-3,-2,2],[4,1,2],X_mm_pp+bar,'B'),\n",
    "    ([-3,-2,-1],[4,1,-1],X_mm_pp+bar,'B'),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify short rules are good degenerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(is_good_degeneration(u,v,p) for u,v,p,_ in growth_rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify some long rules are good degenerations as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = [-3,-2,-3,-3,-2,-2,-2,-3]\n",
    "\n",
    "long_rules = [\n",
    "    ([1,4]+s+[-1],[4,1]+s+[-1],X_pp_pp+(len(s)+1)*bar,'B'),\n",
    "    ([1,4]+s+[2],[4,1]+s+[2],X_pp_pp+(len(s)+1)*bar,'B'),\n",
    "    ([1,4]+s+[3],[4,1]+s+[3],X_pp_pp+(len(s)+1)*bar,'B'),\n",
    "    ([1,4]+s+[4],[4,1]+s+[4],X_pp_pp+(len(s)+1)*bar,'B'),\n",
    "]\n",
    "\n",
    "all(is_good_degeneration(u,v,p) for u,v,p,_ in long_rules)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = [-3,-2,-2,-3,-3]\n",
    "\n",
    "long_rules = [\n",
    "    ([-3,-2]+s+[4],[4,1]+s+[4],X_mm_pp+(len(s)+1)*bar,'B'),\n",
    "    ([-3,-2]+s+[3],[4,1]+s+[3],X_mm_pp+(len(s)+1)*bar,'B'),\n",
    "    ([-3,-2]+s+[2],[4,1]+s+[2],X_mm_pp+(len(s)+1)*bar,'B'),\n",
    "    ([-3,-2]+s+[-1],[4,1]+s+[-1],X_mm_pp+(len(s)+1)*bar,'B'),\n",
    "]\n",
    "\n",
    "\n",
    "all(is_good_degeneration(u,v,p) for u,v,p,_ in long_rules)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify a a good degeneration which is not part of the growth rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_good_degeneration([2,2,3,3],[2,3,2,3],bar+X_pp_pp+bar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Verify additional good degenerations in [GPPSS], Lemma 5.22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = X_pm_mp*X_mp_pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check\n",
    "H*H == 2*bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define extra rules in Lemma 5.22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_rules = [\n",
    "    ([-3,2],[2,-3],H),\n",
    "    ([2,-3],[-3,2],H),\n",
    "    \n",
    "    ([-2,2],[3,-3],H),\n",
    "    ([3,-3],[-2,2],H),\n",
    "    \n",
    "    ([-3,-1],[2,4],H),\n",
    "    ([2,4],[-3,-1],H),\n",
    "    \n",
    "    ([-2,-1],[3,4],H),\n",
    "    ([3,4],[-2,-1],H),\n",
    "    \n",
    "    ([-3,-2],[1,4],H),\n",
    "    ([1,4],[-3,-2],H),\n",
    "    \n",
    "    ([-4,-3],[1,2],H),\n",
    "    ([1,2],[-4,-3],H),\n",
    "    \n",
    "    ([1,-2],[-2,1],X_pm_mp),\n",
    "    ([-2,1],[1,-2],X_pm_mp),\n",
    "    \n",
    "    ([2,-1],[-1,2],X_pm_mp),\n",
    "    ([-1,2],[2,-1],X_pm_mp),\n",
    "    \n",
    "    ([2,-2],[-1,1],X_pm_mp),\n",
    "    ([-1,1],[2,-2],X_pm_mp),\n",
    "    \n",
    "    ([-3,4],[4,-3],X_mp_pm),\n",
    "    ([4,-3],[-3,4],X_mp_pm),\n",
    "    \n",
    "    ([-4,3],[3,-4],X_mp_pm),\n",
    "    ([3,-4],[-4,3],X_mp_pm),\n",
    "    \n",
    "    ([-3,3],[4,-4],X_mp_pm),\n",
    "    ([4,-4],[-3,3],X_mp_pm),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify extra rules are good degenerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(is_good_degeneration(u,v,p) for u,v,p in extra_rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Check some additional good degenerations in Lemma 5.24(iv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeta(k):\n",
    "    p1 = PlumbingPermutation([[('b',i) for i in range(0,k+3)], [('a',k+2)] + [('a',i) for i in range(1,k+2)] + [('a',0)]])\n",
    "    p2 = PlumbingPermutation([[('b',1), ('b',0)] + [('b',i) for i in range(2,k+3)], [('a',1), ('a',0)] + [('a',i) for i in range(2,k+3)]])\n",
    "    p3 = PlumbingPermutation([[('b',k+2)] + [('b',i) for i in range(1,k+2)] + [('b',0)], [('a',i) for i in range(0,k+3)]])\n",
    "    return Plumbing([p1, p2, p3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(is_good_degeneration([4,1]+[-2]*k+[4], [-3,-2]+[-2]*k+[4], zeta(k)) for k in range(7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check additional identity action claim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "p = lambda k: zeta(k) * (X_mm_pp + (k+1)*bar)\n",
    "for k in range(7):\n",
    "    pk = p(k)\n",
    "    v = [-3, -2] + [-2]*k + [4]\n",
    "    for g in Appliance.crystal_appliances(v):\n",
    "        if g*pk != g:\n",
    "            print('Failure!')\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Verify growth rule applicability in Lemma 5.26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "ts = {1:[1,-4], 2:[2,-3], 3:[3,-2], 4:[4,-1]}\n",
    "\n",
    "def is_sublist(S, T):\n",
    "    '''Determines if the list S is a consecutive sublist of the list T.'''\n",
    "    for i in range(len(T)-len(S)+1):\n",
    "        if T[i:i+len(S)] == S:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "growth_rules_Ls = [g[0] for g in growth_rules]\n",
    "for w in [[1,1,4], [1,2,3], [1,2,4], [1,3,2], [1,3,3], [1,3,4], [1,4,4], [2,2,4], [2,3,4], [3,2,4]]:\n",
    "    for v in product(*[ts[i] for i in w]):\n",
    "        v = list(v)\n",
    "        if not any(is_sublist(L, v) for L in growth_rules_Ls):\n",
    "            print('Failure!', v)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Verify monotonicty conditions for short rules in Lemma 5.44 and Lemma 5.48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short rules preserve monotonicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(preserves_monotonicity(v,condition_type) for _,v,_,condition_type\n",
    "                                             in growth_rules\n",
    "                                             if condition_type is not None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check some long rules preserve monotonicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = [-3,-2,-3,-3,-2,-2,-2,-3]\n",
    "\n",
    "long_rules = [\n",
    "    ([1,4]+s+[-1],[4,1]+s+[-1],X_pp_pp+(len(s)+1)*bar,'B'),\n",
    "    ([1,4]+s+[2],[4,1]+s+[2],X_pp_pp+(len(s)+1)*bar,'B'),\n",
    "    ([1,4]+s+[3],[4,1]+s+[3],X_pp_pp+(len(s)+1)*bar,'B'),\n",
    "    ([1,4]+s+[4],[4,1]+s+[4],X_pp_pp+(len(s)+1)*bar,'B'),\n",
    "]\n",
    "\n",
    "all(preserves_monotonicity(v,condition_type) for _,v,_,condition_type in long_rules)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = [-3,-2,-2,-3,-3]\n",
    "\n",
    "long_rules = [\n",
    "    ([-3,-2]+s+[4],[4,1]+s+[4],X_mm_pp+(len(s)+1)*bar,'B'),\n",
    "    ([-3,-2]+s+[3],[4,1]+s+[3],X_mm_pp+(len(s)+1)*bar,'B'),\n",
    "    ([-3,-2]+s+[2],[4,1]+s+[2],X_mm_pp+(len(s)+1)*bar,'B'),\n",
    "    ([-3,-2]+s+[-1],[4,1]+s+[-1],X_mm_pp+(len(s)+1)*bar,'B'),\n",
    "]\n",
    "\n",
    "\n",
    "all(preserves_monotonicity(v,condition_type) for _,v,_,condition_type in long_rules)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Verify lex conditions in Lemma 5.31 and Remark 5.32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "biwords = [CrystalWord([a,b]) for a in LETTERS for b in LETTERS]\n",
    "\n",
    "def satisfies_niceness(ab, cd, proper_labelings, verbose = False):\n",
    "    a,b = ab\n",
    "    c,d = cd\n",
    "    \n",
    "    # Condition (i):\n",
    "    if not (tilde_letter(a)==tilde_letter(b)==tilde_letter(c)==tilde_letter(d) or (tilde_letter(a)<tilde_letter(c) and ab.is_tilde_lex_smaller(cd)) ):\n",
    "        if verbose:\n",
    "            print(\"Condition (i) fails\")\n",
    "        return False\n",
    "    \n",
    "    # Condition (ii)\n",
    "    for labeling in proper_labelings:\n",
    "        if labeling[0] == ab and cd.is_tilde_lex_smaller(labeling[1]):\n",
    "            if verbose:\n",
    "                print(\"Condition (ii) fails because of {}\".format(str(labeling)))\n",
    "            return False\n",
    "        \n",
    "    # Condition (iii)\n",
    "    for labeling in proper_labelings:\n",
    "        pq, ts = labeling\n",
    "        if cd.is_tilde_lex_smaller(ts) or cd.tilde() == ts.tilde():\n",
    "            if pq.is_tilde_lex_smaller(ab):\n",
    "                if verbose:\n",
    "                    print(\"Condition (iii) fails because of {}\".format(str(labeling)))\n",
    "                return False\n",
    "    \n",
    "    # Condition (iv)\n",
    "    for gamma in range(3):\n",
    "        for beta in range(gamma, gamma+3):\n",
    "            for alpha in range(beta, beta+3):\n",
    "                u = [1]*alpha + [2]*beta + [3]*gamma\n",
    "                if CrystalWord(u+[c,d]).is_heighest_weight():\n",
    "                    if not CrystalWord(u+[a,b]).is_heighest_weight():\n",
    "                        if verbose:\n",
    "                            print(\"Condition (iv) fails because of {}\".format(u))\n",
    "                        return False\n",
    "    \n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([1, 2], [2, 1]),\n",
       " ([1, 3], [3, 1]),\n",
       " ([1, 4], [4, 1]),\n",
       " ([2, 4], [4, 2]),\n",
       " ([3, 4], [4, 3])]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute all possible nice labelings for X_pp_pp\n",
    "def is_pp_pp_labeling(ab,cd):\n",
    "    a, b = ab\n",
    "    c, d = cd\n",
    "    return a!=b and c!=d and a>0 and b>0 and c>0 and d>0 and set(ab) == set(cd)\n",
    "\n",
    "proper_pp_pp_labelings = [(ab,cd) for ab in biwords for cd in biwords if is_pp_pp_labeling(ab,cd)]\n",
    "\n",
    "[labeling for labeling in proper_pp_pp_labelings if satisfies_niceness(*labeling, proper_pp_pp_labelings)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([1, 2], [-3, -4]),\n",
       " ([1, 3], [-2, -4]),\n",
       " ([1, 4], [-2, -3]),\n",
       " ([2, 3], [-1, -4]),\n",
       " ([2, 4], [-1, -3]),\n",
       " ([3, 4], [-1, -2])]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute all possible nice labelings for X_pp_mm\n",
    "def is_pp_mm_labeling(ab,cd):\n",
    "    a, b = ab\n",
    "    c, d = cd\n",
    "    return a>0 and b>0 and c<0 and d<0 and set([a,b,-c,-d]) == set([1,2,3,4])\n",
    "\n",
    "proper_pp_mm_labelings = [(ab,cd) for ab in biwords for cd in biwords if is_pp_mm_labeling(ab,cd)]\n",
    "\n",
    "[labeling for labeling in proper_pp_mm_labelings if satisfies_niceness(*labeling, proper_pp_mm_labelings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([1, -1], [-2, 2]),\n",
       " ([1, -2], [-2, 1]),\n",
       " ([1, -3], [-3, 1]),\n",
       " ([1, -4], [-4, 1]),\n",
       " ([2, -1], [-1, 2]),\n",
       " ([2, -2], [-1, 1]),\n",
       " ([3, -1], [-1, 3]),\n",
       " ([4, -1], [-1, 4])]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute all possible nice labelings for X_pm_mp\n",
    "def is_pm_mp_labeling(ab,cd):\n",
    "    a, b = ab\n",
    "    c, d = cd\n",
    "    return a!=-c and b!=-d and a>0 and b<0 and c<0 and d>0 and set([a,-c]) == set([-b,d])\n",
    "\n",
    "proper_pm_mp_labelings = [(ab,cd) for ab in biwords for cd in biwords if is_pm_mp_labeling(ab,cd)]\n",
    "\n",
    "[labeling for labeling in proper_pm_mp_labelings if satisfies_niceness(*labeling, proper_pm_mp_labelings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([-1, 4], [4, -1]),\n",
       " ([-2, 4], [4, -2]),\n",
       " ([-3, 3], [4, -4]),\n",
       " ([-3, 4], [4, -3]),\n",
       " ([-4, 1], [1, -4]),\n",
       " ([-4, 2], [2, -4]),\n",
       " ([-4, 3], [3, -4]),\n",
       " ([-4, 4], [3, -3])]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute all possible nice labelings for X_mp_pm\n",
    "def is_mp_pm_labeling(ab,cd):\n",
    "    a, b = ab\n",
    "    c, d = cd\n",
    "    return a!=-c and b!=-d and a<0 and b>0 and c>0 and d<0 and set([a,-c]) == set([-b,d])\n",
    "\n",
    "proper_mp_pm_labelings = [(ab,cd) for ab in biwords for cd in biwords if is_mp_pm_labeling(ab,cd)]\n",
    "\n",
    "[labeling for labeling in proper_mp_pm_labelings if satisfies_niceness(*labeling, proper_mp_pm_labelings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([-2, -1], [4, 3]),\n",
       " ([-3, -1], [4, 2]),\n",
       " ([-3, -2], [4, 1]),\n",
       " ([-4, -1], [3, 2]),\n",
       " ([-4, -2], [3, 1]),\n",
       " ([-4, -3], [2, 1])]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute all possible nice labelings for X_mm_pp\n",
    "def is_mm_pp_labeling(ab,cd):\n",
    "    a, b = ab\n",
    "    c, d = cd\n",
    "    return a<0 and b<0 and c>0 and d>0 and set([-a,-b,c,d]) == set([1,2,3,4])\n",
    "\n",
    "proper_mm_pp_labelings = [(ab,cd) for ab in biwords for cd in biwords if is_mm_pp_labeling(ab,cd)]\n",
    "\n",
    "[labeling for labeling in proper_mm_pp_labelings if satisfies_niceness(*labeling, proper_mm_pp_labelings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([-2, -1], [-1, -2]),\n",
       " ([-3, -1], [-1, -3]),\n",
       " ([-4, -1], [-1, -4]),\n",
       " ([-4, -2], [-2, -4]),\n",
       " ([-4, -3], [-3, -4])]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute all possible nice labelings for X_mm_mm\n",
    "def is_mm_mm_labeling(ab,cd):\n",
    "    a, b = ab\n",
    "    c, d = cd\n",
    "    return a!=b and c!=d and a<0 and b<0 and c<0 and d<0 and set(ab) == set(cd)\n",
    "\n",
    "proper_mm_mm_labelings = [(ab,cd) for ab in biwords for cd in biwords if is_mm_mm_labeling(ab,cd)]\n",
    "\n",
    "[labeling for labeling in proper_mm_mm_labelings if satisfies_niceness(*labeling, proper_mm_mm_labelings)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
